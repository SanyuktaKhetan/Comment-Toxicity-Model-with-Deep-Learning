{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFb9k_xcF548"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nCv021v2GJY6"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8ye0_KvQrTsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pHnr_LGHImZ3"
      },
      "outputs": [],
      "source": [
        "data_dir = '/content/drive/My Drive/Colab Notebooks/jigsaw-toxic-comment-classification'\n",
        "\n",
        "# Full path to the train.csv file\n",
        "train_file_path = os.path.join(data_dir, 'train.csv')\n",
        "print(train_file_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1p_88KOzN59c"
      },
      "outputs": [],
      "source": [
        "print(os.listdir(data_dir))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IC-4-PyqPcbr"
      },
      "outputs": [],
      "source": [
        "train_file_path = '/content/drive/MyDrive/Colab Notebooks/jigsaw-toxic-comment-classification/train.csv/train.csv'\n",
        "print(os.path.isfile(train_file_path))  # This should print True if the file exists\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnsg1NI9cNo_"
      },
      "source": [
        "Read csv file data to pandas DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQqIZHp9SDYh"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv(train_file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7jAdeULcRQk"
      },
      "source": [
        "Display first 10 rows of DataFrame or dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPsig2CdwAyk"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paC5Dz6EcZ5Q"
      },
      "source": [
        "Display Last 10 rows of DataFrame or dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bsd2NcLmwPbJ"
      },
      "outputs": [],
      "source": [
        "df.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_jaa9PaccGa"
      },
      "source": [
        "used to access a specific entry in a pandas DataFrame\n",
        "index value 159489"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oTY4cDpTwU97"
      },
      "outputs": [],
      "source": [
        "df.iloc[159489]['comment_text']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMIvKAnAc4pq"
      },
      "source": [
        "used to select a specific row from a subset of columns in a pandas DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nP5D6MJ2xhF4"
      },
      "outputs": [],
      "source": [
        "df[df.columns[2:]].iloc[6]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4LH4HqVdF3Q"
      },
      "source": [
        "used to filter rows in a pandas DataFrame where the value in the toxic column is equal to 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-aq9UH97ytUa"
      },
      "outputs": [],
      "source": [
        "df[df['toxic']==1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yth-iPiNdd0q"
      },
      "source": [
        "Calculates number of Toxic comments in the DataFrame\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2OLOT5uMzSQP"
      },
      "outputs": [],
      "source": [
        "total_toxic_comments = df[df['toxic'] == True].shape[0]\n",
        "print(f\"Total count of toxic comments: {total_toxic_comments}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qdRupDjQz_2O"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import TextVectorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBSEUQLd2KnY"
      },
      "outputs": [],
      "source": [
        "x=df['comment_text']\n",
        "y=df[df.columns[2:]].values\n",
        "print(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJTzAt9x3VGg"
      },
      "outputs": [],
      "source": [
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m--ZoDJfte06"
      },
      "outputs": [],
      "source": [
        "MAX_FEATURES=200000 #number of words in vocab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9Hk_QdX8nVD"
      },
      "source": [
        "The below code helps to convert text data to numberical values for the input to the model.\n",
        "It sets the max-vocabulary words to be used, fixes the length of the sentence and defines the outptu to be int format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehX4j0bD5qWB"
      },
      "outputs": [],
      "source": [
        "#initailize the text vectorization layer\n",
        "vectorizer=TextVectorization(max_tokens=MAX_FEATURES, #number of words in the vocab\n",
        "                            output_sequence_length=1800, #length of a sentence\n",
        "                            output_mode='int') #output mode must be integer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtIR-Lxd9Xbd"
      },
      "source": [
        "x below is a series object of Panda Series. It contains the text data from 'comment_text\" column.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8EWOmspqGWFB"
      },
      "outputs": [],
      "source": [
        "type(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aWR0cgz9wym"
      },
      "source": [
        ".value attribute converts the data into numPy array format.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "numpy.ndarray stands for N dimensional array\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nGkrEh-T6I4E"
      },
      "outputs": [],
      "source": [
        "type(x.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A7MAVFhrCVyO"
      },
      "outputs": [],
      "source": [
        "vectorizer.adapt(x.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ynnnQI--LMoA"
      },
      "outputs": [],
      "source": [
        "vectorizer(\"Hello World, How are you ? hope you are fine\")[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_9XIVonGykt"
      },
      "outputs": [],
      "source": [
        "vectorizer.get_vocabulary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mij_L-0qszA1"
      },
      "outputs": [],
      "source": [
        "vectorizer.adapt(x.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fa5JRVT_s7rM"
      },
      "outputs": [],
      "source": [
        "vectorized_text=vectorizer(x.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UdyzhrfGWaWa"
      },
      "outputs": [],
      "source": [
        "len(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aBn9GcqntE-9"
      },
      "outputs": [],
      "source": [
        "vectorized_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j9qdfJK_tKL5"
      },
      "outputs": [],
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((vectorized_text, y))\n",
        "dataset =dataset.cache()\n",
        "dataset = dataset.shuffle(160000) #buffer size 160000\n",
        "dataset = dataset.batch(16)\n",
        "dataset = dataset.prefetch(8) # helps prevent bottlenecks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fv1odYTKb_o6"
      },
      "outputs": [],
      "source": [
        "batch_x,batch_y=dataset.as_numpy_iterator().next()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBpBktSxGg3K"
      },
      "source": [
        "16 comments each of length 1800\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "luvgyFL0cZrq"
      },
      "outputs": [],
      "source": [
        "batch_x.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3T5aG0BGm7h"
      },
      "source": [
        "16 correcponding labels with respect to x\n",
        "16 samples in the batch, each with 6 label categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zeTWHIq0dIk5"
      },
      "outputs": [],
      "source": [
        "batch_y.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NB4BO9rRGvo_"
      },
      "source": [
        "Total number of batches in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZIzyCCDgdu0i"
      },
      "outputs": [],
      "source": [
        "len(dataset) #length in batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOiaPrjNdO5q"
      },
      "outputs": [],
      "source": [
        "train = dataset.take(int(len(dataset)*0.7)) # 70% of total data\n",
        "val = dataset.skip(int(len(dataset)*0.7)).take(int(len(dataset)*0.2)) #.skip will skip the 70% data and then get another 20% data\n",
        "test = dataset.skip(int(len(dataset)*0.9)).take(int(len(dataset)*0.1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqY-8yQ-eRO1"
      },
      "outputs": [],
      "source": [
        "len(train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VO3tJSXUeeBT"
      },
      "outputs": [],
      "source": [
        "len(val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jn61DwU-egek"
      },
      "outputs": [],
      "source": [
        "len(test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZM917nFH5Oa"
      },
      "source": [
        "onverts the TensorFlow dataset train into a NumPy iterator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjbOWrg-eoc5"
      },
      "outputs": [],
      "source": [
        "train_generator = train.as_numpy_iterator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dc43Q4W8ernR"
      },
      "outputs": [],
      "source": [
        "train_generator.next()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0c3Kdk-_fO3K"
      },
      "outputs": [],
      "source": [
        "#create a Sequential Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-MhpspwUfSWs"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dropout, Bidirectional, Dense, Embedding #layers used to build deep learning layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhsHDAeCf44L"
      },
      "outputs": [],
      "source": [
        "model = Sequential() #instantiate the sequential api to add the various layers to the model\n",
        "#create the embedding layer\n",
        "model.add(Embedding(MAX_FEATURES+1, 32)) # +1 is for unknown words\n",
        "# one embedding per word\n",
        "#Bidirectional passes the info in both directions backward and forward\n",
        "model.add(Bidirectional(LSTM(32, activation='tanh')))  # 32 different LSTM units\n",
        "# feature extractor of fully cocnnected layers\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "#final output layer converts value between 0 to 1\n",
        "model.add(Dense(6, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AWZ4bGM0lwUv"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='BinaryCrossentropy', optimizer='adam',metrics=['accuracy'])  #configure learning process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UpTR6ydHlunF"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j40p6TAt1LXw",
        "outputId": "62952d0f-df24-48ba-a2fc-b179f179d946"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m6981/6981\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11885s\u001b[0m 2s/step - accuracy: 0.9426 - loss: 0.0837 - val_accuracy: 0.9933 - val_loss: 0.0449\n",
            "Epoch 2/3\n",
            "\u001b[1m6110/6981\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m24:01\u001b[0m 2s/step - accuracy: 0.9862 - loss: 0.0455"
          ]
        }
      ],
      "source": [
        "history = model.fit(train, epochs=3, validation_data=val)  #train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upC85Toj6A0t"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8CEwk4sQ6U9c"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8,5))\n",
        "pd.DataFrame(history.history).plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U0VS_ZFi9pwt"
      },
      "outputs": [],
      "source": [
        "input_text=vectorizer('You freaking suck')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NigeE2Zs94ZX"
      },
      "outputs": [],
      "source": [
        "batch = test.as_numpy_iterator().next()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bHH1ui21_9Cg"
      },
      "outputs": [],
      "source": [
        "test.as_numpy_iterator().next()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-B6c97uy-O1s"
      },
      "outputs": [],
      "source": [
        "model.predict(np.expand_dims(input_text,0 ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hdqNEywy_R5w"
      },
      "outputs": [],
      "source": [
        "res =model.predict(np.expand_dims(input_text,0 ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6lG71z_M-1W"
      },
      "outputs": [],
      "source": [
        "(res > 0.5).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5qYh5mMzV3F"
      },
      "outputs": [],
      "source": [
        "batch_X, batch_y = test.as_numpy_iterator().next()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "elKmBUHXzaVm"
      },
      "outputs": [],
      "source": [
        "(model.predict(batch_X) > 0.5).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uLsgHE-8zb_p"
      },
      "outputs": [],
      "source": [
        "res.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V4PFeX4xzhKF"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.metrics import Precision, Recall, CategoricalAccuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20Y69dOxzjou"
      },
      "outputs": [],
      "source": [
        "pre = Precision()\n",
        "re = Recall()\n",
        "acc = CategoricalAccuracy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OGjrJ9BUzl-B"
      },
      "outputs": [],
      "source": [
        "for batch in test.as_numpy_iterator():\n",
        "    # Unpack the batch\n",
        "    X_true, y_true = batch\n",
        "    # Make a prediction\n",
        "    yhat = model.predict(X_true)\n",
        "\n",
        "    # Flatten the predictions\n",
        "    y_true = y_true.flatten()\n",
        "    yhat = yhat.flatten()\n",
        "\n",
        "    pre.update_state(y_true, yhat)\n",
        "    re.update_state(y_true, yhat)\n",
        "    acc.update_state(y_true, yhat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H5fVjfLhzqsF"
      },
      "outputs": [],
      "source": [
        "print(f'Precision: {pre.result().numpy()}, Recall:{re.result().numpy()}, Accuracy:{acc.result().numpy()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65NncehazzfC"
      },
      "outputs": [],
      "source": [
        "!pip install gradio jinja2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GcyncA_az1gz"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZmqUopjz25R"
      },
      "outputs": [],
      "source": [
        "model.save('toxicity.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5RomIPXxz5No"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.load_model('toxicity.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tLAVBuNyz8vN"
      },
      "outputs": [],
      "source": [
        "input_str = vectorizer('hey i freaken hate you!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0OwPDju6z9bz"
      },
      "outputs": [],
      "source": [
        "res = model.predict(np.expand_dims(input_str,0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PoWUF2Md0ACY"
      },
      "outputs": [],
      "source": [
        "res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LL_XBFUJ0BtK"
      },
      "outputs": [],
      "source": [
        "def score_comment(comment):\n",
        "    vectorized_comment = vectorizer([comment])\n",
        "    results = model.predict(vectorized_comment)\n",
        "\n",
        "    text = ''\n",
        "    for idx, col in enumerate(df.columns[2:]):\n",
        "        text += '{}: {}\\n'.format(col, results[0][idx]>0.5)\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UqvqTDeh0Dvi"
      },
      "outputs": [],
      "source": [
        "interface = gr.Interface(fn=score_comment,\n",
        "                         inputs=gr.inputs.Textbox(lines=2, placeholder='Comment to score'),\n",
        "                        outputs='text')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5yiB5dRS0J_e"
      },
      "outputs": [],
      "source": [
        "interface.launch(share=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}